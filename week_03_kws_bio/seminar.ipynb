{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seminar (Week 3)\n",
    "\n",
    "Dataset: https://disk.yandex.ru/d/B-bVBC3_1qQltw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataclasses\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from sklearn.decomposition import PCA\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as torch_data\n",
    "import torchaudio\n",
    "import tqdm.notebook as tqdm\n",
    "import urllib\n",
    "\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'https://cloud-api.yandex.net/v1/disk/public/resources/download?'\n",
    "public_key = 'https://disk.yandex.ru/d/B-bVBC3_1qQltw'\n",
    "final_url = base_url + urllib.parse.urlencode(dict(public_key=public_key))\n",
    "response = requests.get(final_url)\n",
    "download_url = response.json()['href']\n",
    "!wget -O biometry_sem.tar.gz \"{download_url}\"\n",
    "!tar -xf biometry_sem.tar.gz -C data_sem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = 'data_sem'\n",
    "DEVICE = 'mps'\n",
    "TARGETS = os.path.join(DATA, 'targets.csv')\n",
    "IN_DIM = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch_data.Dataset):\n",
    "    @dataclasses.dataclass\n",
    "    class Item:\n",
    "        feats: torch.tensor\n",
    "        speaker: int\n",
    "        age: int\n",
    "        gender: int\n",
    "        room: int\n",
    "\n",
    "    def __init__(self, transform: nn.Module, speakers=(1, 2, 3), genders=(0, 1)):\n",
    "        targets = pd.read_csv(TARGETS)\n",
    "        self._speakers = {}\n",
    "        self._data = []\n",
    "        for _, row in tqdm.tqdm(targets.iterrows(), total=len(targets)):\n",
    "            if int(row.speaker.split('_')[0]) not in speakers:\n",
    "                continue\n",
    "            if row.gender not in genders:\n",
    "                continue\n",
    "            path = os.path.join(DATA, row.audio)\n",
    "            wav = torchaudio.load(path)[0]\n",
    "            feats = transform(wav)[0]\n",
    "            speaker = self._speakers.get(row.speaker, len(self._speakers))\n",
    "            if speaker not in self._speakers:\n",
    "                self._speakers[row.speaker] = len(self._speakers)\n",
    "            self._data.append(self.Item(feats, speaker, row.age, row.gender, int(row.speaker.split('_')[0])))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self._data[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self._data)\n",
    "    \n",
    "    def speakers(self):\n",
    "        return len(self._speakers)\n",
    "    \n",
    "def collate_fn(batch: list[Dataset.Item]):\n",
    "    feats = [item.feats for item in batch]\n",
    "    max_len = max([feat.shape[1] for feat in feats])\n",
    "    X = torch.zeros((len(batch), IN_DIM, max_len))\n",
    "    for idx, feat in enumerate(feats):\n",
    "        X[idx,:,:feat.shape[1]] = feat\n",
    "    Y = torch.tensor([item.speaker for item in batch], dtype=torch.long, device=DEVICE)\n",
    "    age = [item.age for item in batch]\n",
    "    gender = [item.gender for item in batch]\n",
    "    room = [item.room for item in batch]\n",
    "    return X.to(DEVICE), Y, age, gender, room"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset(torchaudio.transforms.MFCC(n_mfcc=40))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model\n",
    "\n",
    "Train simple model for biometrics classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        super().__init__()\n",
    "        self._body = None  # <YOUR CODE IS HERE>\n",
    "        self._head = None  # <YOUR CODE IS HERE>\n",
    "\n",
    "    def forward(self, X):\n",
    "        emb = self._body(X)  # <YOUR CODE IS HERE>\n",
    "        return self._head(emb), emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model: nn.Module, epochs=10, batch_size=256):\n",
    "    opt = optim.Adam(model.parameters())\n",
    "    data = torch_data.DataLoader(dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "    losses = []\n",
    "    accs = []\n",
    "    for _ in range(epochs):\n",
    "        loss_sum = 0\n",
    "        acc_sum = 0\n",
    "        batches = 0\n",
    "        for X, Y, _, _, _ in tqdm.tqdm(data):\n",
    "            logits, _ = model.forward(X)\n",
    "            logits = logits.squeeze()\n",
    "            loss = F.cross_entropy(logits, Y)\n",
    "            with torch.no_grad():\n",
    "                acc = torch.sum(torch.argmax(logits, dim=-1) == Y) / X.shape[0]\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            loss_sum += loss.item()\n",
    "            acc_sum += acc.item()\n",
    "            batches += 1\n",
    "        losses.append(loss_sum / batches)\n",
    "        accs.append(acc_sum / batches)\n",
    "        clear_output()\n",
    "        fig, axis = plt.subplots(1, 2, figsize=(15, 7))\n",
    "        axis[0].plot(losses)\n",
    "        axis[1].plot(accs)\n",
    "        plt.show()\n",
    "        print('Train loss:', losses[-1], 'Accuracy:', accs[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(IN_DIM, dataset.speakers()).to(DEVICE)\n",
    "train(model, epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare embeddings\n",
    "\n",
    "Prepare embeddings of trained model, project to lower dimensional space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = []\n",
    "ages = []\n",
    "genders = []\n",
    "rooms = []\n",
    "data = torch_data.DataLoader(dataset, batch_size=256, collate_fn=collate_fn)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for X, _, age, gender, room in tqdm.tqdm(data):\n",
    "        _, emb = model.forward(X)\n",
    "        embeddings.extend(emb.squeeze().cpu().data.numpy())\n",
    "        ages.extend(age)\n",
    "        genders.extend(gender)\n",
    "        rooms.extend(room)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <YOUR CODE IS HERE>\n",
    "emb2dim = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot different classes\n",
    "\n",
    "Plot embeddings for different classes by age, gender and room conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gender\n",
    "for gen in [0, 1]:\n",
    "    cur_emb = [emb for emb, gender in zip(emb2dim, genders) if gender == gen]\n",
    "    print(np.mean(cur_emb, axis=0))\n",
    "    x_limits = np.quantile([x for x, _ in cur_emb], [0.01, 0.99])\n",
    "    y_limits = np.quantile([y for _, y in cur_emb], [0.01, 0.99])\n",
    "    cur_emb = np.array(\n",
    "        [(x, y) for x, y in cur_emb if x_limits[0] <= x <= x_limits[1] and y_limits[0] <= y <= y_limits[1]]\n",
    "    )\n",
    "    indexes = np.random.choice(np.arange(len(cur_emb)), size=500, replace=False)\n",
    "    cur_emb = cur_emb[indexes]\n",
    "    plt.plot([x for x, _ in cur_emb], [y for _, y in cur_emb], '.', label=gen)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
